# íŒŒì¼ëª…: geocode_apartments.py
# ì¹´ì¹´ì˜¤ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì†Œë¥¼ ìœ„ê²½ë„ ì¢Œí‘œë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

import pandas as pd
import requests
from tqdm import tqdm
import time
from dotenv import load_dotenv
import os 
# --------------------------------------------------------------------------
# ì¤‘ìš”: 1ë‹¨ê³„ì—ì„œ ë°œê¸‰ë°›ì€ ë³¸ì¸ì˜ REST API í‚¤ë¥¼ ì•„ë˜ì— ë¶™ì—¬ë„£ì–´ ì£¼ì„¸ìš”!
# --------------------------------------------------------------------------
KAKAO_REST_API_KEY = os.getenv("KAKAO_REST_API_KEY")
# --------------------------------------------------------------------------


def get_coordinates_kakao(address, use_keyword=False):
    """
    ì¹´ì¹´ì˜¤ ë¡œì»¬ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì†Œë¡œë¶€í„° ìœ„ê²½ë„ ì¢Œí‘œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    use_keyword: Trueë©´ í‚¤ì›Œë“œ ê²€ìƒ‰, Falseë©´ ì£¼ì†Œ ê²€ìƒ‰
    """
    headers = {"Authorization": f"KakaoAK {KAKAO_REST_API_KEY}"}
    
    if use_keyword:
        url = f"https://dapi.kakao.com/v2/local/search/keyword.json?query={address}"
    else:
        url = f"https://dapi.kakao.com/v2/local/search/address.json?query={address}"
    
    try:
        response = requests.get(url, headers=headers, timeout=5)
        response.raise_for_status()
        data = response.json()
        
        if data['documents']:
            location = data['documents'][0]
            if use_keyword:
                return (float(location['y']), float(location['x']))
            else:
                return (float(location['y']), float(location['x']))
        else:
            return (None, None)
            
    except requests.exceptions.RequestException as e:
        print(f"API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return (None, None)
    except Exception as e:
        print(f"ì£¼ì†Œ ë³€í™˜ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: '{address}' | ì˜¤ë¥˜: {e}")
        return (None, None)

# --- ì½”ë“œ ì‹¤í–‰ ì‹œì‘ ---

# 1. CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
try:
    residential_df = pd.read_csv('./data/residential.csv')
    office_df = pd.read_csv('./data/office.csv')
    print("íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
except FileNotFoundError:
    print("ì˜¤ë¥˜: 'residential.csv' ë˜ëŠ” 'office.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# 2. ë°ì´í„° í•©ì¹˜ê¸° ë° ì£¼ì†Œ ìƒì„±
combined_df = pd.concat([residential_df, office_df], ignore_index=True)

# ê±´ë¬¼ëª… ì •ì œ í•¨ìˆ˜
def clean_building_name(name):
    """ê±´ë¬¼ëª…ì—ì„œ ë¶ˆí•„ìš”í•œ ë¬¸ìì—´ ì œê±°"""
    if pd.isna(name):
        return ""
    
    # ê´„í˜¸ ë‚´ìš© ì œê±°
    name = str(name).split('(')[0].strip()
    
    # ì•„íŒŒíŠ¸, ë¹Œë¼, ì˜¤í”¼ìŠ¤í…” ë“± ê³µí†µ ì ‘ë¯¸ì‚¬ ì œê±°
    suffixes_to_remove = ['ì•„íŒŒíŠ¸', 'APT', 'ë¹Œë¼', 'ë¹Œë¦¬ì§€', 'ì˜¤í”¼ìŠ¤í…”', 'íƒ€ì›Œ', 'ì„¼í„°', 'í”Œë ˆì´ìŠ¤', 
                         'í•˜ìš°ìŠ¤', 'ë§¨ì…˜', 'íŒ°ë¦¬ìŠ¤', 'ìºìŠ¬', 'íŒŒí¬', 'ê°€ë“ ', 'í', 'ë·°', 'ì‹œí‹°']
    
    for suffix in suffixes_to_remove:
        if name.endswith(suffix):
            name = name[:-len(suffix)].strip()
    
    return name

# ë‹¤ì–‘í•œ ì£¼ì†Œ í˜•íƒœ ìƒì„±
combined_df['ë‹¨ì§€ëª…_ì •ì œ'] = combined_df['ë‹¨ì§€ëª…'].apply(clean_building_name)
combined_df['ê¸°ë³¸ì£¼ì†Œ'] = 'ì„œìš¸ ' + combined_df['êµ¬'] + ' ' + combined_df['ë™']
combined_df['ìƒì„¸ì£¼ì†Œ'] = combined_df['ê¸°ë³¸ì£¼ì†Œ'] + ' ' + combined_df['ë‹¨ì§€ëª…_ì •ì œ']
combined_df['ì›ë³¸ì£¼ì†Œ'] = 'ì„œìš¸ ' + combined_df['êµ¬'] + ' ' + combined_df['ë™'] + ' ' + combined_df['ë‹¨ì§€ëª…']

# ì¤‘ë³µ ì£¼ì†Œ ì œê±°ë¥¼ ìœ„í•´ ì›ë³¸ì£¼ì†Œ ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬
unique_data = combined_df.drop_duplicates(subset=['ì›ë³¸ì£¼ì†Œ']).copy()
print(f"ì´ {len(unique_data)}ê°œì˜ ê³ ìœ í•œ ì£¼ì†Œì— ëŒ€í•œ ì¢Œí‘œë¥¼ ì¹´ì¹´ì˜¤ APIë¡œ ì°¾ìŠµë‹ˆë‹¤.")

# 3. ì¢Œí‘œ ë³€í™˜ ì‹¤í–‰ (ê°œì„ ëœ ë‹¤ë‹¨ê³„ ì‹œë„)
def get_coordinates_with_fallback(row):
    """ë‹¤ë‹¨ê³„ fallbackìœ¼ë¡œ ì¢Œí‘œ ê²€ìƒ‰"""
    attempts = [
        (row['ì›ë³¸ì£¼ì†Œ'], False, "ì›ë³¸ ì£¼ì†Œ"),
        (row['ìƒì„¸ì£¼ì†Œ'], False, "ì •ì œëœ ì£¼ì†Œ"),
        (row['ì›ë³¸ì£¼ì†Œ'], True, "ì›ë³¸ í‚¤ì›Œë“œ ê²€ìƒ‰"),
        (row['ìƒì„¸ì£¼ì†Œ'], True, "ì •ì œëœ í‚¤ì›Œë“œ ê²€ìƒ‰"),
        (row['ê¸°ë³¸ì£¼ì†Œ'], False, "ê¸°ë³¸ ì£¼ì†Œ"),
        (row['ê¸°ë³¸ì£¼ì†Œ'], True, "ê¸°ë³¸ í‚¤ì›Œë“œ ê²€ìƒ‰")
    ]
    
    for address, use_keyword, method in attempts:
        if pd.isna(address) or address.strip() == '':
            continue
            
        lat, lon = get_coordinates_kakao(address, use_keyword)
        if lat is not None and lon is not None:
            return lat, lon, method, address
        time.sleep(0.02)
    
    return None, None, "ëª¨ë“  ì‹œë„ ì‹¤íŒ¨", ""

coordinate_results = {}
for idx, row in tqdm(unique_data.iterrows(), desc="ì£¼ì†Œ ë³€í™˜ ì§„í–‰ë¥ ", total=len(unique_data)):
    lat, lon, method, used_address = get_coordinates_with_fallback(row)
    
    if lat is None:
        print(f"'{row['ì›ë³¸ì£¼ì†Œ']}' ì¢Œí‘œ ë³€í™˜ ì‹¤íŒ¨")
    
    coordinate_results[row['ì›ë³¸ì£¼ì†Œ']] = {
        'lat': lat, 
        'lon': lon, 
        'method': method,
        'used_address': used_address
    }

# 4. ì›ë³¸ ë°ì´í„°ì— ì¢Œí‘œ ì¶”ê°€
combined_df['ìœ„ë„'] = combined_df['ì›ë³¸ì£¼ì†Œ'].map(lambda addr: coordinate_results.get(addr, {}).get('lat'))
combined_df['ê²½ë„'] = combined_df['ì›ë³¸ì£¼ì†Œ'].map(lambda addr: coordinate_results.get(addr, {}).get('lon'))
combined_df['ë³€í™˜ë°©ë²•'] = combined_df['ì›ë³¸ì£¼ì†Œ'].map(lambda addr: coordinate_results.get(addr, {}).get('method'))
combined_df['ì‚¬ìš©ëœì£¼ì†Œ'] = combined_df['ì›ë³¸ì£¼ì†Œ'].map(lambda addr: coordinate_results.get(addr, {}).get('used_address'))

# 5. ê²°ê³¼ íŒŒì¼ ì €ì¥
output_filename = 'real_estate_with_coordinates_kakao.csv'
combined_df.to_csv(output_filename, index=False, encoding='utf-8-sig')

# 6. ê²°ê³¼ í†µê³„ ì¶œë ¥
total_count = len(combined_df)
success_count = combined_df['ìœ„ë„'].notna().sum()
failure_count = total_count - success_count

print("\n--- âœ… ì‘ì—… ì™„ë£Œ ---")
print(f"ì •í™•í•œ ìœ„ê²½ë„ ì¢Œí‘œê°€ ì¶”ê°€ëœ íŒŒì¼ì´ '{output_filename}'ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
print(f"\nğŸ“Š ë³€í™˜ ê²°ê³¼ í†µê³„:")
print(f"- ì „ì²´ ë°ì´í„°: {total_count:,}ê°œ")
print(f"- ì„±ê³µ: {success_count:,}ê°œ ({success_count/total_count*100:.1f}%)")
print(f"- ì‹¤íŒ¨: {failure_count:,}ê°œ ({failure_count/total_count*100:.1f}%)")

# ë³€í™˜ ë°©ë²•ë³„ í†µê³„
method_stats = combined_df['ë³€í™˜ë°©ë²•'].value_counts()
print(f"\nğŸ” ë³€í™˜ ë°©ë²•ë³„ ì„±ê³µ í†µê³„:")
for method, count in method_stats.items():
    if method != "ëª¨ë“  ì‹œë„ ì‹¤íŒ¨":
        print(f"- {method}: {count:,}ê°œ")

print("\nê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ):")
print(combined_df[['ë‹¨ì§€ëª…', 'ì›ë³¸ì£¼ì†Œ', 'ìœ„ë„', 'ê²½ë„', 'ë³€í™˜ë°©ë²•']].head())